{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misspelling detection and correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: This notebook depends upon the the Retrotech dataset. If you have any issues, please rerun the [Setting up the Retrotech Dataset](../ch4/1.ch4-setting-up-the-retrotech-dataset.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import re\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_sample=pd.read_json(\"../data/temp/signal_sample.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Tokenize queries and count word frequencies. \n",
    "Check word frequency distribut quantiles. The quantile will help decide cut off point for potential misspells and corrections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "word_list = defaultdict(int)\n",
    "\n",
    "for query in signal_sample[\"query_s\"]:\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') \n",
    "    tokened = tokenizer.tokenize(query.lower())\n",
    "    \n",
    "    for token in tokened:\n",
    "        if token not in stop_words and len(token) > 3 and not token.isdigit():  #drop stopwords and digit only tokens\n",
    "            # and only consider token length > 3, since hard to judge whether a very short token is misspelled or not\n",
    "            word_list[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 2., 3., 5., 9.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(np.array(list(word_list.values())), [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: compute metadata needed for word matching. \n",
    "consider word with low count as misspelling condidates, with high count as correctly spelled candidates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "misspell_candidates = []\n",
    "correction_candidates = []\n",
    "misspell_counts = []\n",
    "correction_counts = []\n",
    "misspell_length = []\n",
    "correction_length = []\n",
    "misspell_initial = []\n",
    "correction_initial = []\n",
    "\n",
    "for k, v in word_list.items():\n",
    "    if v == 1:\n",
    "        misspell_candidates.append(k)\n",
    "        misspell_counts.append(v)\n",
    "        misspell_length.append(len(k))\n",
    "        misspell_initial.append(k[0])\n",
    "    if v >= 9:\n",
    "        correction_candidates.append(k)\n",
    "        correction_counts.append(v)\n",
    "        correction_length.append(len(k))\n",
    "        correction_initial.append(k[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "misspell_candidates_df = pd.DataFrame({\"misspell\":misspell_candidates, \"misspell_counts\":misspell_counts, \"misspell_length\":misspell_length,\"initial\":misspell_initial})\n",
    "correction_candidates_df = pd.DataFrame({\"correction\":correction_candidates, \"correction_counts\":correction_counts, \"correction_length\":correction_length,\"initial\":correction_initial})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Find potential matches \n",
    "based on edit distance and whether word initial is the same or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_match(len1, len2, edit_dist): #allow longer words have more edit distance\n",
    "    match = 0\n",
    "    min_length = min(len1, len2)\n",
    "    if min_length < 8:\n",
    "        if edit_dist == 1: match = 1\n",
    "    elif min_length < 11:\n",
    "        if edit_dist <= 2: match = 1\n",
    "    else:\n",
    "        if edit_dist == 3: match = 1\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_candidates = pd.merge(misspell_candidates_df, correction_candidates_df, on=\"initial\")\n",
    "#join missepll list with correction list based on whether they share the same initials to reduce matching time. \n",
    "matches_candidates[\"edit_dist\"] = matches_candidates.apply(lambda row: nltk.edit_distance(row.misspell,row.correction), axis=1)\n",
    "matches_candidates[\"good_match\"] = matches_candidates.apply(lambda row: good_match(row.misspell_length, row.correction_length, row.edit_dist),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matches_candidates[matches_candidates[\"good_match\"] == 1].drop([\"initial\",\"good_match\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: rank potential matched corrections \n",
    "based on edit distance and correction word frequency. shorter edit distance and higher word count will be prefered. only the top one correction is selected for final matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.sort_values(by=['misspell', 'edit_dist', 'correction_counts'], ascending=[True, True, False])\n",
    "matches_final = matches.groupby('misspell').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misspell</th>\n",
       "      <th>misspell_counts</th>\n",
       "      <th>misspell_length</th>\n",
       "      <th>correction</th>\n",
       "      <th>correction_counts</th>\n",
       "      <th>correction_length</th>\n",
       "      <th>edit_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accesorios</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>accessories</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accwsories</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>accessories</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aceer</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>acer</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ameria</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>america</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>antanna</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>antenna</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>appe</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>apple</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aquois</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>aquos</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>archam</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>arkham</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>asis</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>asus</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>atenna</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>antenna</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     misspell  misspell_counts  misspell_length   correction  \\\n",
       "0  accesorios                1               10  accessories   \n",
       "1  accwsories                1               10  accessories   \n",
       "2       aceer                1                5         acer   \n",
       "3      ameria                1                6      america   \n",
       "4     antanna                1                7      antenna   \n",
       "5        appe                1                4        apple   \n",
       "6      aquois                1                6        aquos   \n",
       "7      archam                1                6       arkham   \n",
       "8        asis                1                4         asus   \n",
       "9      atenna                1                6      antenna   \n",
       "\n",
       "   correction_counts  correction_length  edit_dist  \n",
       "0                 16                 11          2  \n",
       "1                 16                 11          2  \n",
       "2                 40                  4          1  \n",
       "3                 23                  7          1  \n",
       "4                 27                  7          1  \n",
       "5                 93                  5          1  \n",
       "6                 10                  5          1  \n",
       "7                 19                  6          1  \n",
       "8                 53                  4          1  \n",
       "9                 27                  7          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_final.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
